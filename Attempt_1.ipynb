{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 1\n",
    "\n",
    "* NaNs replaced by zeros\n",
    "* Using QuantileTransformer on target\n",
    "* Using random 80/20 train/test split\n",
    "* XGBoost on RF using parameters from GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import math\n",
    "from sklearn import model_selection, ensemble, metrics, linear_model, preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 990025  991020  992016  993012  994009  995006  996004  997002  998001\n",
      "  999000 1000000 1001000 1002001 1003002 1004004 1005006 1006009 1007012\n",
      " 1008016 1009020 1010025 1011030 1012036 1013042 1014049 1015056]\n",
      "(26,)\n",
      "[1007012 1008016 1009020 1010025 1011030 1012036 1013042 1014049 1015056\n",
      " 1016064]\n",
      "(10,)\n",
      "['Andromeda Galaxy (M31)' 'Andromeda I' 'Andromeda II' 'Andromeda III'\n",
      " 'Andromeda IX']\n",
      "(181,)\n"
     ]
    }
   ],
   "source": [
    "#Test dataset contains objects only of latest 10 years,\n",
    "#including unmentioned in train data latest year 1016064\n",
    "unique_years = data['galactic year'].unique()\n",
    "print (unique_years)\n",
    "print (unique_years.shape)\n",
    "\n",
    "print(np.sort(test['galactic year'].unique()))\n",
    "print(test['galactic year'].unique().shape)\n",
    "\n",
    "unique_names = data['galaxy'].unique()\n",
    "unique_names = np.sort(unique_names)\n",
    "print (unique_names[:5])\n",
    "print(unique_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's map all galactic years to years with increment of 1 year\n",
    "# and map all galaxies to their unique integer key\n",
    "\n",
    "#dictionary for replacement of galactic years with normal years\n",
    "di = {val: ind+1 for ind, val in enumerate(np.append(unique_years,\n",
    "                                                     1016064))}\n",
    "#dictionary for replacement of names with integer keys\n",
    "di_names = {val: ind+1 for ind, val in enumerate(unique_names)}\n",
    "data.replace({'galactic year':di}, inplace=True)\n",
    "test.replace({'galactic year':di}, inplace=True)\n",
    "\n",
    "data.replace({'galaxy':di_names}, inplace=True)\n",
    "test.replace({'galaxy':di_names}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score as CVS\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.compose import TransformedTargetRegressor as TransTargReg\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# getting X and y\n",
    "X = data.iloc[:, 2:-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "#creating a target transformer (normal)\n",
    "qt = QuantileTransformer(n_quantiles=1000, output_distribution='normal' )\n",
    "\n",
    "#normalize\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "(X_train, X_test, y_train,\n",
    " y_test) = model_selection.train_test_split(X, y,\n",
    "          test_size = 0.2, shuffle=True, random_state=425)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012996969418034781\n",
      "0.027789754076831437\n"
     ]
    }
   ],
   "source": [
    "#Let's use RandomForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest = RandomForestRegressor(n_estimators=2000,\n",
    "                               criterion='mse',\n",
    "                               max_depth=None,\n",
    "                               min_samples_split=2,\n",
    "                               min_samples_leaf=2,\n",
    "                               max_features=26,\n",
    "                               n_jobs=3,\n",
    "                               min_weight_fraction_leaf=0.0,\n",
    "                               max_leaf_nodes=None,\n",
    "                               min_impurity_decrease=0.0,\n",
    "                               min_impurity_split=None,\n",
    "                               bootstrap=True,\n",
    "                               oob_score=False,\n",
    "                               random_state=None,verbose=0,\n",
    "                               warm_start=False,\n",
    "                               ccp_alpha=0.0,\n",
    "                               max_samples=None,)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "print(MSE(y_train, forest.predict(X_train))**0.5)\n",
    "print(MSE(y_test, forest.predict(X_test))**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(forest.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012228787669184718\n",
      "0.027486190084097663\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "XGB = TransTargReg(xgb.XGBRegressor(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=2000,\n",
    "    verbosity=1,\n",
    "    silent=None,\n",
    "    objective='reg:squarederror',\n",
    "    booster='gbtree',\n",
    "    n_jobs=3,\n",
    "    nthread=None,\n",
    "    gamma=0,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=0.5,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=0.3,\n",
    "    reg_alpha=1,\n",
    "    reg_lambda=0,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=42,\n",
    "    seed=None,\n",
    "    missing=None,\n",
    "    importance_type='gain'),\n",
    "                   qt)\n",
    "XGB.fit(X_train, y_train)\n",
    "\n",
    "print(MSE(y_train, XGB.predict(X_train))**0.5)\n",
    "print(MSE(y_test, XGB.predict(X_test))**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.4, 0.6, 0.8, 1. ])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.2, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=TransformedTargetRegressor(check_inverse=True, func=None,\n",
       "                                                  inverse_func=None,\n",
       "                                                  regressor=XGBRegressor(base_score=0.5,\n",
       "                                                                         booster='gbtree',\n",
       "                                                                         colsample_bylevel=1,\n",
       "                                                                         colsample_bynode=0.3,\n",
       "                                                                         colsample_bytree=1,\n",
       "                                                                         gamma=0,\n",
       "                                                                         importance_type='gain',\n",
       "                                                                         learning_rate=0.01,\n",
       "                                                                         max_delta_step=0,\n",
       "                                                                         max_depth=8,\n",
       "                                                                         min_child_weight=1,\n",
       "                                                                         missing=None,\n",
       "                                                                         n_est...\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'regressor__learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'regressor__max_depth': [4, 5, 6, 7, 8, 9],\n",
       "                         'regressor__reg_alpha': [0, 1],\n",
       "                         'regressor__reg_lambda': [0, 1],\n",
       "                         'regressor__subsample': [0.2, 0.4, 0.6000000000000001,\n",
       "                                                  0.8, 1.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_root_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSearch for XGBoost RF hyperparameters\n",
    "param_grid = {\n",
    "    'regressor__max_depth': [4,5,6,7,8,9],\n",
    "    'regressor__learning_rate': [0.1, 0.01, 0.001],\n",
    "#    'regressor__n_estimators': [200, 400, 800, 1200],\n",
    "    'regressor__subsample': list(np.linspace(0.2, 1, 5)),\n",
    "#    'regressor__colsample_bynode': [0.2, 0.3, 0.4],\n",
    "    'regressor__reg_alpha': [0,1],\n",
    "    'regressor__reg_lambda': [0,1],\n",
    "    \n",
    "}\n",
    "XGB_GSCV = model_selection.GridSearchCV(XGB,\n",
    "                                        param_grid=param_grid,\n",
    "                                        n_jobs=None,\n",
    "                                        scoring='neg_root_mean_squared_error',\n",
    "                                        cv=10)\n",
    "XGB_GSCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor__learning_rate': 0.01,\n",
       " 'regressor__max_depth': 6,\n",
       " 'regressor__reg_alpha': 0,\n",
       " 'regressor__reg_lambda': 0,\n",
       " 'regressor__subsample': 1.0}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_GSCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027827222929303935"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(y_test, XGB_GSCV.best_estimator_.predict(X_test))**0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
