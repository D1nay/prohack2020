{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 1\n",
    "\n",
    "* NaNs replaced by zeros\n",
    "* Using QuantileTransformer on target\n",
    "* Using random 80/20 train/test split\n",
    "* XGBoost on RF using parameters from GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import math\n",
    "from sklearn import model_selection, ensemble, metrics, linear_model, preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 990025  991020  992016  993012  994009  995006  996004  997002  998001\n",
      "  999000 1000000 1001000 1002001 1003002 1004004 1005006 1006009 1007012\n",
      " 1008016 1009020 1010025 1011030 1012036 1013042 1014049 1015056]\n",
      "(26,)\n",
      "[1007012 1008016 1009020 1010025 1011030 1012036 1013042 1014049 1015056\n",
      " 1016064]\n",
      "(10,)\n",
      "['Andromeda Galaxy (M31)' 'Andromeda I' 'Andromeda II' 'Andromeda III'\n",
      " 'Andromeda IX']\n",
      "(181,)\n"
     ]
    }
   ],
   "source": [
    "#Test dataset contains objects only of latest 10 years,\n",
    "#including unmentioned in train data latest year 1016064\n",
    "unique_years = data['galactic year'].unique()\n",
    "print (unique_years)\n",
    "print (unique_years.shape)\n",
    "\n",
    "print(np.sort(test['galactic year'].unique()))\n",
    "print(test['galactic year'].unique().shape)\n",
    "\n",
    "unique_names = data['galaxy'].unique()\n",
    "unique_names = np.sort(unique_names)\n",
    "print (unique_names[:5])\n",
    "print(unique_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's map all galactic years to years with increment of 1 year\n",
    "# and map all galaxies to their unique integer key\n",
    "\n",
    "#dictionary for replacement of galactic years with normal years\n",
    "di = {val: ind+1 for ind, val in enumerate(np.append(unique_years,\n",
    "                                                     1016064))}\n",
    "#dictionary for replacement of names with integer keys\n",
    "di_names = {val: ind+1 for ind, val in enumerate(unique_names)}\n",
    "data.replace({'galactic year':di}, inplace=True)\n",
    "test.replace({'galactic year':di}, inplace=True)\n",
    "\n",
    "data.replace({'galaxy':di_names}, inplace=True)\n",
    "test.replace({'galaxy':di_names}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score as CVS\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.compose import TransformedTargetRegressor as TransTargReg\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import QuantileTransformer, quantile_transform\n",
    "\n",
    "# getting X and y\n",
    "X = data.iloc[:, 0:-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "#creating a target transformer (normal)\n",
    "qt = QuantileTransformer(n_quantiles=1000, output_distribution='normal' )\n",
    "\n",
    "#normalize\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "(X_train, X_test, y_train,\n",
    " y_test) = model_selection.train_test_split(X, y,\n",
    "          test_size = 0.2, shuffle=True, random_state=425)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004783013588373652\n",
      "0.019910947597162425\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "XGB = TransTargReg(xgb.XGBRegressor(\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=500,\n",
    "    verbosity=1,\n",
    "    silent=None,\n",
    "    objective='reg:squarederror',\n",
    "    booster='gbtree',\n",
    "    n_jobs=3,\n",
    "    nthread=None,\n",
    "    gamma=0,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=0.5,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=0.3,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=42,\n",
    "    seed=None,\n",
    "    missing=None,\n",
    "    importance_type='gain'),\n",
    "                   qt)\n",
    "XGB.fit(X_train, y_train)\n",
    "\n",
    "print(MSE(y_train, XGB.predict(X_train))**0.5)\n",
    "print(MSE(y_test, XGB.predict(X_test))**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
