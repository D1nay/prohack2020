{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Journal of insights\n",
    "## So far\n",
    "The Contest dataset is the UNDP data that has undergone some transformations. Assuming the target variable was calculated using the original UNDP data and if I can match galaxies with the respective countries, there exists an opportunity to significantly reduce the inherent noise present in the Contest data. This can be a breakthrough. \n",
    "\n",
    "\n",
    "## 14.06\n",
    "1) Galaxy \"NGC 1560\" is the \"World\" statistic/country in the UNDP tables. I found this out by analyzing the outlier in the population plot.  \n",
    "2) This eased me into hypothesizing that the original UNDP columns were transformed to the Contest dataset by:\n",
    "* shifting all values by a certain constant for a given columnâ€”could be a multiplier of median, mean or some other statistics\n",
    "* adding (gaussian?) noise to each element of the column with a certain standard deviation for a given column.  \n",
    "This is supported by the histograms and KDE plots for each attribute.  \n",
    "\n",
    "3) With this knowledge it should be easier to match galaxies with their respective countries.  \n",
    "4) Based on analyzing the population outliers \"Phoenix II\" could be \"China\" and \"Andromeda XXVI\" is probably \"India\"\n",
    "\n",
    "After some light research it turns out that for our high-dimensional data it may be more reasonable to employ the L1 metric to find the nearest neigbour (elaborated idea will be later). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
